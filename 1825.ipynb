{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Récupération du data de Flight Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser \n",
    "import threading\n",
    "    # je récupère le data toutes les 10785 secondes \n",
    "def scrappingdata():\n",
    "    threading.Timer(10785, Test01).start()\n",
    "    webbrowser.open('https://www.flighthub.com/fr/flight/search?type=roundtrip&seg0_from=YUL&seg0_to=PAR&seg0_date=2018-07-18&seg1_date=2018-07-25&seg1_from=PAR&seg1_from_code=PAR&seg1_to=YUL&seg1_to_code=YUL&seg2_from_code=YUL&seg3_from_code=YUL&seg4_from_code=YUL&num_adults=1&num_children=0&num_infants=0&num_infants_lap=0&seat_class=%C3%89conomique&campaign=133&search_id=dd1de99d91df073c70c9140000ad8cd2&flexible_search_id=dd1de99d91df073c70c9140000ad8cd2')\n",
    "\n",
    "Test01()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test0():\n",
    "    import os\n",
    "    import csv\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import threading\n",
    "    # je récupère le data toutes les 10800 secondes (3h)\n",
    "    threading.Timer(10800, test0).start ()\n",
    "\n",
    "    requete = requests.get(\"https://www.flighthub.com/fr/flight/search?type=roundtrip&seg0_from=YUL&seg0_to=PAR&seg0_date=2018-07-18&seg1_date=2018-07-25&seg1_from=PAR&seg1_from_code=PAR&seg1_to=YUL&seg1_to_code=YUL&seg2_from_code=YUL&seg3_from_code=YUL&seg4_from_code=YUL&num_adults=1&num_children=0&num_infants=0&num_infants_lap=0&seat_class=%C3%89conomique&campaign=133&search_id=dd1de99d91df073c70c9140000ad8cd2&flexible_search_id=dd1de99d91df073c70c9140000ad8cd2\")\n",
    "    page = requete.content\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "    #h1 = soup.find(\"h1\", {\"class\": \"ico-after ico-tutorials\"})\n",
    "    #print(h1)\n",
    "\n",
    "    #h3 = soup.find_all(\"span\", {\"class\": \"price-currency\"})\n",
    "    #h4 = soup.find_all(\"span\", {\"class\": \"price-whole\"})\n",
    "    #h5 = soup.find_all(\"span\", {\"class\": \"price-decimal\"})\n",
    "    #h6 = soup.find_all(\"span\", {\"class\": \"price-fraction\"})\n",
    "    #h4 = soup.find_all(\"div\", {\"class\": \"packages-os-flight-number\"})\n",
    "    #print(h3)\n",
    "    #print(Cp)\n",
    "    #print(h3)\n",
    "    h3 = soup.find_all(\"li\", {\"class\": \"amatrix-item\"})\n",
    "    liste_titre = [elt.text.strip() for elt in h3]\n",
    "    #liste_titre2 = [elt.string.strip() for elt in h4]\n",
    "    #liste_titre3 = [elt.string.strip() for elt in h5]\n",
    "    #liste_titre4 = [elt.string.strip() for elt in h6]\n",
    "    #liste_description = [elt.text.strip() for elt in h4]\n",
    "\n",
    "    #liste_description = [elt.string.strip() for elt in desc]\n",
    "\n",
    "    j = len(liste_titre)\n",
    "    i = 0\n",
    "    with open(\"2018071820180725.csv\", \"w\", encoding=\"utf-8\") as fichier:\n",
    "\n",
    "        writer = csv.writer(fichier, delimiter=' ' \n",
    "                            ,quotechar='|'\n",
    "                            ,escapechar='|'\n",
    "                            ,skipinitialspace=False\n",
    "                            ,quoting=csv.QUOTE_NONE\n",
    "                           )\n",
    "        while i < j:\n",
    "            writer.writerow((liste_titre[i]))#,liste_titre2[i],liste_titre3[i],liste_titre4[i]))\n",
    "            i+=1\n",
    "        \n",
    "test0()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Étant donné que le data finit à la même place, je déplace et renomme chaque fichier créé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test2():\n",
    "    import threading\n",
    "    threading.Timer(10805, test2).start ()\n",
    "    import os.path\n",
    "    import glob\n",
    "    import shutil\n",
    "    import csv\n",
    "    import time\n",
    "    import os\n",
    " \n",
    "    for monfich in glob.glob('C:/Users/Tgrotta/2018071820180725.csv'):\n",
    "        monfich=os.path.basename(monfich)\n",
    "        shutil.move(monfich,\"C:/Users/Tgrotta/Documents/CiblePrixBillets\")       \n",
    "        #os.rename(\"C:/Users/Tgrotta/Documents/cible/toto25.csv\", \"C:/Users/Tgrotta/Documents/cible/tata25.csv\")\n",
    "        fichier=\"C:/Users/Tgrotta/Documents/CiblePrixBillets/2018071820180725.csv\"\n",
    "        nom, ext = os.path.splitext(fichier)\n",
    "        dateiso = time.strftime('%Y_%m_%d_%H_%M_%S')\n",
    "        os.rename(fichier, nom + '_' + dateiso + ext)\n",
    "        \n",
    "test2()       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
